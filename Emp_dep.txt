case class Department(id:Int,name:String)
case class Employee(id:Int,f_name:String,l_name:String)

// Create departments 
// Create employees

val dep1=new Department(1,"IT")
val dep2=new Department(2,"HR")
val dep3=new Department(3,"Hardware")
val dep4=new Department(4,"Marketing")


val emp1 =new Employee(1,"prathap","kudupu")
val emp2 =new Employee(2,"sandeep","shetty")
val emp3 =new Employee(3,"sacheen","achan")
val emp4 =new Employee(4,"jatheen","achan")


// Create dataframes for departments
val dep=Seq(dep1,dep2)
val dp_df1 =dep.toDF()
display(df1)

val emp=Seq(emp1,emp2)
val dp_df1=emp.toDF()

display(dp_df1)


// UNION OF TO DF
val emp_un=Seq(emp3,emp4)
val dp_df2=emp_un.toDF()

val un_DF=dp_df1.unionAll(dp_df2)
display(un_DF)

# FUNCTION FOR FLATTEN A DATAFRAME

import org.apache.spark.sql._
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

implicit class DataFrameFlattener(df: DataFrame) {
  def flattenSchema: DataFrame = {
    df.select(flatten(Nil, df.schema): _*)
  }

  protected def flatten(path: Seq[String], schema: DataType): Seq[Column] = schema match {
    case s: StructType => s.fields.flatMap(f => flatten(path :+ f.name, f.dataType))
    case other => col(path.map(n => s"`$n`").mkString(".")).as(path.mkString(".")) :: Nil
  }
}


